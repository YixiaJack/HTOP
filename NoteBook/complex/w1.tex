\chapter[Functions of Complex Variables]{Functions of Complex Variables}
\section[Lecture 1 (02-03) -- {Complex numbers}]{Lecture 1 (02-03)Complex numbers}

\subsection{Introduction}

You know the sets $$ (R,+,\times ) and (Q,+,\times) $$
$ Q(\sqrt{2})=\{a+b\sqrt{2} | a,b \in Q\} $ $Q(\sqrt{2})$, they are infinite sets.


\begin{definition}[Fields]{}
    We say that a set $F$ together with two binary operations, called addition $+$,$F \times F \to F$, and multiplication $\times$, $F \times F \to F$ satisfying: 
    \begin{itemize}
        \item associativity $(a+b)+c=a+(b+c)$
        \item commutativity  $a+b=b+a,ab=ba$
        \item existence of identities\\there is a $O \in F$ such that $a+O=a$ for all $a \in F$\\there is a $1 \in F$ such that $a \times 1=a$ for all $a \in F$
        \item existence of inverses \\for every $a \in F$ there is a $b \in F$ such that $a+b=O$\\for every $a \in F$ there is a $b \in F$ such that $a \times b=1$
        \item distributivity\\$a \times (b+c)=a \times b+a \times c$
    \end{itemize}
    \end{definition}

\begin{example}[Fields]{}
    \begin{itemize}
        \item For every prime number $p$, and $n \geq 0$,$n \in N$, there is a field ($F_{p^n},+,\times$) with $p^n=q$ elements (cardinality $q$).
        \item (C,+,x) is a field
    \end{itemize}
    \end{example}
Question: ($R^d,+$),$d\geq 2$, is there a multiplication, $\times$ such that ($R^d,+,x$) is a field?
\begin{itemize}
    \item $R^2$ , sclar product, $x \cdot y=x_1y_1+x_2y_2 \in R$ is not a field because $R^2 \times R^2 \rightarrow R$.
    \item cross product, not satisfying Definition 1 and 5.
    \item d=2, there is a good defination of multiplication, $(R^2,+,\times)\cong (C,+,\times)$.
\end{itemize}
\begin{lemma}{1}{}
    Consider the vector space $(R^2,+)$
    \\Define the multiplication:
    $(a,b) \times (c,d) = (ac-bd,ad+bc)$
    \\Then $(R^2,+,\times)$ is a field.
    \end{lemma}
Proof: 
\begin{itemize}
    \item You can check that $\times$ is commutative and satisfies associativity and distributivity.
    \item We can check $(1,0)$ is a multiplication identity.
    \item also if $(a,b) \neq (0,0)$, then $$(a,b) \times (\frac{a}{a^2+b^2} ,\frac{-b}{a^2+b^2})=(\frac{a^2+b^2}{a^2+b^2} ,\frac{-ab+ab}{a^2+b^2})=(1,0)$$
\end{itemize}

\section[Lecture 2 (02-05) -- {Complex numbers}]{Lecture 2 (02-05)Complex numbers}

\subsection{The algebra of complex numbers}
It is important to classify sets:
\\in  Set Theory: bijection
\\in Topology: homeomorphism
\\For \textbf{Fields}: isomorphism
\begin{definition}[isomorphism]{}
   We say that fields $F$ and $F'$ are isomorphic if there exists a funtion $$i:F \rightarrow F'$$ which is a bijection and preserve the binary operations  $$i(a+b)=i(a)+i(b)$$ and $$i(ab)=i(a)i(b)$$.
   \\i is called an isomorphism and we write $F \cong F'$
    \end{definition}
\textbf{Comments:}
\\There is a unque field up to isomorphism of order (its cardinality)$$
    p^n: F_{p^n}
$$ 
\begin{definition}[subfield]{}
Given a field (F,+,x), we say that (E,+,x) is a subfield of (F,+,x) if E $\subset$ F and the addition of multiplication of E is the same addition and multiplication of F. 
\end{definition}
\begin{example}[subfield]{}
$$
    Q \subset R
$$ 
$$
    Q\subset Q(\sqrt{2}) \subset R \subset R^2
$$ 
\end{example}
\begin{definition}[complex number]{}
Let F be a field such that:\begin{itemize}
\item R is a subfield of F
\item there is an element $i \in F$ which is the root of the equation $$ x^2+1=0 (i^2=-1)$$
\end{itemize}
Then we define the field of complex numbers $ C $ as $$C=\{x\in F:x=\alpha +i\beta ,\alpha, \beta \in R \}$$
\end{definition}
\textbf{Comments:}  
\begin{itemize}
    \item We need to show that there is at least one field $ F $ satisfying these properties.
    \\ \textbf{Actually, $ (F,+,\times) =(R,+,\times)$ satisfies these properties.}
    \item $ R'=\{x\in R:x=(\alpha ,0),\alpha \in R\} \cong R \rightarrow $ R is a subfield of $ R^2 $ .
    \item Define $ i:=(0,1)\in R^2 $ $$
        (a,b)\times (c,d):=(ac-bd,ad+bc) 
    $$  Then, $$
        i^2={(0,1)}^2=(0,1)\times (0,1)=(-1,0)
    $$ 
\end{itemize}
\begin{example}[exercise]{}
Set of $ 2\times 2 $  real matrices of the form 
$$
    \begin{pmatrix}
        a & b\\
        -b & a
    \end{pmatrix}, a,b \in R $$
    \\This set together with the standard addition and multiplication of matrices is a field and it is isomorphic to $ (R^2,+,\times) $ . 
\\$ F=R^2,C=R^2 $ 
\end{example}
\textbf{Comments:}  
\\It turns out that any defination of $ C $ is unique (up to isomorphisms).
\begin{lemma}{}{}
Let $ F $ and $ F' $ be two fields satisfying the properties of the definition of complex numbers, then call $\mathbb{C} and \mathbb{C}'$ the corresponding complex number fields.
\\Then $ \mathbb{C} \cong \mathbb{C}' $.
\end{lemma}
\textbf{Proof:}
\\Call $ i \in $ $\mathbb{C}$ and $ i' \in  \mathbb{C}' $the square roots $ -1 $.
\\Then:
    $$
        f: \mathbb{C} \rightarrow \mathbb{C}' \text{  defined as  } f(\alpha +i\beta)=\alpha +i'\beta \text{  is an isomorphism}
    $$ 
$$
    z=\alpha +i\beta, z'=\alpha '+i'\beta', w=\gamma  +i\delta , w'=\gamma '+i'\delta'
$$ 
\begin{lemma}{}{}
Consider the vetor space $ (\mathbb{R},+)$.Then any multiplication '$ \times $' defined in this vector space which transforms it into a field $ (\mathbb{R},+,\times) $ ,is such that $ (\mathbb{R},+,\times) \cong \mathbb{C} $.  

\end{lemma}
\textbf{Proof:}
\\Consider the elements$$
    (1,0) \text{    and   } j=(0,1) \in \mathbb{R}^2
$$ 
\\Then any elemnt of $ \mathbb{R}^2 $ can be written as$ \alpha +j\beta ,\alpha ,\beta \in \mathbb{R}$
\\Then$$
    j^2=a+jb, a,b \in \mathbb{R}
$$ Then,
$$
    j^2-jb=a, j^2-2\frac{jb}{2}=a \rightarrow j^2-2\frac{jb}{2}+\frac{b^2}{4}=a+\frac{b^2}{4}
$$ 
\begin{equation}
    {(j+\frac{b}{2})}^2=a+\frac{b^2}{4}  \label{eq3}
\end{equation}
\textbf{Define:}$ i=\frac{j-\frac{b}{2}}{\sqrt{a+\frac{b^2}{4}}} $ 
\\\textbf{Claim:}
$$
    a+\frac{b^2}{4}<0
$$ 
If:$$
    a+\frac{b^2}{4} \geq 0
$$ 
\\Then \eqref{eq3} can be written as

$$ \rightarrow ((j-\frac{b}{2})+\sqrt{a+\frac{b^2}{4}})((j-\frac{b}{2})-\sqrt{a+\frac{b^2}{4}})=0$$ 
\\either $$ j-\frac{b}{2}=\sqrt{a+\frac{b^2}{4}} ,j-\frac{b}{2}=-\sqrt{a+\frac{b^2}{4}}$$ 

\section[Recitation 1(02-07)]{Complex numbers}
The field of rationals $ \mathcal{Q} $ is the fractional field of the integral domian $ \mathcal{Z} $.
\\With the metrice \begin{align*}{}{}
d(x,y)=|x-y|
\\|x|=max\{x,-x\}, \forall x, y \in \mathcal{R}
\end{align*}
\\The fielf $\mathcal{Q}$ is not a complete ,metrice space.
\\Its completion $\mathbb{R}$, nevertheless is not algebraically closed.
\\For instance, $ f(x)=x^2+1 $, doesn't split in $ \mathbb{R} $.
\\So we define the spliting field for $ f(x) $ over $ \mathbb{R} $ 
\\i.e. the smallest field extension of $ \mathbb{R} $ such that $ f(x) $ has roots.
\\
\\Consider the principle ideal $ <f(x)> $ in $ \mathbb{R}[x] $ 
\\since $ f(x) $ is irreducible, then $ <f(x)> $ si a maximal ideal.
\\Then the quotient ring $ \mathbb{C}=\frac{\mathbb{R}[x]}{<f(x)>} $  is a field!   
\\which is the spilting field of $f(x)$
\\* The field $ \mathbb{C} $ has no further spilting extensions! All polynomials in $ \mathbb{C}[x] $ split in $ \mathbb{C} $.
\\So as soon as we forced one polynomial. $ f(x)=x^2+1 $ to have roots, we in fact imposed that all polynomials have roots.
\\
\\\textbf{Topology:}
\\ The Topology of $ \mathbb{C} $ is isomorphic to $ \mathbb{R}^2 $. 
\\Thus $ \mathbb{C} $ is locally compact, but not compact space.
\\The Alexandroff compactification says that we can add a point at infinity to $ \mathbb{C} $ so that $ \mathbb{C}\cup\{\infty\} $  compact.
\begin{definition}[Alexandroff compactification]{}
\begin{itemize}
\item A set $ U\supseteq \mathbb{C}\cup\{\infty\} $ is an open neighborhood of $\{ \infty \}$ if $ U=\mathbb{C}\cup \{\infty\}\ K $ When $ K \supseteq \mathbb{C} $ .
\end{itemize}
\end{definition}
$\mathbb{C}\cup\{\infty\}$ is called the Riemann sphere.
\begin{definition}[Holomorphic Functions]{}
A function $ f:\Omega\rightarrow \mathbb{C} $ is holomorphic where $ \Omega \subseteq \mathbb{C} $ is holomorphic iff:
\begin{align*}{}{}
\lim_{z\rightarrow z_0}\frac{f(z)-f(z_0)}{z-z_0}=f'(z_0) \text{ exists}, \forall z_0 \in \Omega
\\f(z)=f(x,y)=u(x,y)+iv(x,y),where z=x+iy \in \Omega
\\u(z)=Re(f(z)),v(z)=Im(f(z))
\end{align*}
\end{definition}
$ f:\Omega \rightarrow \mathbb{C} $ being holomorphic of course implies that $ u,v:\Omega \rightarrow \mathbb{R}^2 $ differentiable.
\\If we take $ f(z_0)=z_0=0 $ and we write 
$$
    \pdv{}{z}=\frac{1}{2}(\pdv{}{x}-i\pdv{}{y}), \pdv{}{\bar{z}}=\frac{1}{2}(\pdv{}{x}+i\pdv{}{y})
$$ 
\\Then,
$$
    \frac{f(x)-f(z_0)}{z-z_0}=\frac{f(z)}{z}={(\pdv{f}{z})}_{(z_0=0)}+\frac{\bar{z}}{z}{(\pdv{f}{\bar{z}})}_{(z_0=0)}+o(z)
$$ 
\\For real $ z\rightarrow 0 $ , we have $ \frac{\bar{z}}{z}=1 $  , and for purely imaginary $ z\rightarrow 0 $ , we have $ \frac{\bar{z}}{z}=-1 $.
\\we have to restrict $\pdv{f}{z}=0$
\\\textbf{Cauchy-Riemann equations:}
$$\begin{cases}
    \pdv{u}{x}=\pdv{v}{y}
    \\\pdv{u}{y}=-\pdv{v}{x}
\end{cases}$$
$$
    f'(z)=\pdv{f}{z}=(\pdv{u}{x}+i\pdv{v}{x})(x,y), \text{where } z=x+iy \in \Omega
$$ 
\\Nevertheless, $ f $ being holomorphic is not equivalent to say $ f $ satisfies the Cauchy-Riemann equations.
\\Indeed we take $ f(z)=\frac{z^5}{{|z|}^4} \text{  on  } \mathbb{C}\textbackslash \{0\}   $  and $ f(0)=0 $.
\\We can observe that $ f(z) $ satisfies the Cauchy-Riemann equations on $ \mathbb{C} $ but $ f $ is not even coutinuous at $ z=0 $.
\begin{theorem}[Looman Menchoff Theorrem]{}
A continuous function $ f:\Omega \cup \mathbb{C} \rightarrow \mathbb{C} $ is holomorphic iff $ f $ satisfies the Cauchy-Riemann equations.
\end{theorem}
\begin{align*}{}{}
\forall f,g \in H(\Omega)
\\(fg)&=f'g+fg'
\\(\frac{f}{g})&=\frac{f'g-fg'}{g^2}
\\(g\circ f)'(z)&=g'(f(z))\cdot f'(z)
\end{align*}
\section{Lecture 3 (02-10) -- {Algebraic Structure of Complex numbers}}
\subsection{Algebraic Structure of Complex numbers}
\begin{lemma}[]{}
Consider $ (\mathbb{R}^2,+) $ as a vector space. Then any definition of multiplication on $ \mathbb{R}^2 $ compatible with the vector space structure, which transforms $ \mathbb{R}^2 $ into a field, defines a field isomorphism with $ \mathbb{C} $.

\end{lemma}
\textbf{Comments:}
\\The assumption that the multiplication is compatible with the vector space structure means that the scalar multiplication coincides with the field multiplication in the following space.
$$
    (\mathbb{R}^2,+,\times)
$$ 
and $ 1\in \mathbb{R} $ is the multiplicative identity 
\\then$$
 au=(a1)\times u, a\in \mathbb{R}   
$$ 
Let $ L=\{a1: a\in \mathbb{R}\} $
\\Then $ L $ is isomorphic with $ \mathbb{R} $ 
\\The addition in $ \mathbb{R}^2 $ as a vector space coincides with the addition in $ \mathbb{R}^2  $ as a field.
\\\textbf{Proof of the Lemma:}
\\Essentially we have to find a $ i \in \mathbb{R}^2 $ such that $ i^2=-1 $ 
\\Since $ \mathbb{R}^2 $ is a two-dimentional vector space , if we pick any $ j\in \mathbb{R}^2\backslash L $ 
\\We know that $ 1,j,j^2 $ must be linearly dependent.
\\Then thus must exist $ a,b\in \mathbb{R} $ such that $ aj^2+bj+c1=0 $ 
\\Then, \begin{align*}{}{}
a(j^2)+2\frac{b}{2a}j+c=0\\
a{(j+\frac{b}{2a})}^2+c-a{(\frac{b}{2a})}^2=0\\
{(j+\frac{b}{2a})}^2=\frac{1}{a}(-c+a{(\frac{b}{2a})}^2)
\end{align*}
Necesaarily, $ -c+a{(\frac{b}{2a})}^2<0 $
\\Define 
$$
    i=\frac{\sqrt{a}(j+\frac{b}{2a})}{\sqrt{-a{(\frac{b}{2a})}^2+c}}
$$
\subsection{Square roots} 
Every complex number has a square root.
\\Also we can write the 2 square roots in a quite explicit way(related to fundamental theorem of algebra).
\begin{lemma}[]{}
$$ \sqrt{\alpha+i\beta}=\pm(\sqrt{\frac{\alpha+\sqrt{\alpha^2+\beta^2}}{2}}+\frac{\beta}{|\beta|}\sqrt{\frac{-\alpha+\sqrt{\alpha^2+\beta^2}}{2}}) $$ 
\end{lemma}
\textbf{Proof:}
\\(Notation for complex numbers: $ \alpha+i\beta,x+iy,\cdots $)
\\We need to find $ z=x+iy $ such that $ z^2={(x+iy)}^2\alpha+i\beta $ 
\\So $ x^2-y^2=\alpha, 2xy=\beta $ 
\\Now,
$$
    (x^2+y^2)^2=(x^2-y^2)^2+4x^2y^2=\alpha^2+\beta^2
$$ 
So, \begin{align*}{}{}
x^2+y^2&=\sqrt{\alpha^2+\beta^2}\\
x^2-y^2&=\alpha\\
\Rightarrow x^2&=\frac{\alpha+\sqrt{\alpha^2+\beta^2}}{2}\\
y^2&=\frac{-\alpha+\sqrt{\alpha^2+\beta^2}}{2}\\
x&=\pm\sqrt{\frac{\alpha+\sqrt{\alpha^2+\beta^2}}{2}}\\
y&=\pm\sqrt{\frac{-\alpha+\sqrt{\alpha^2+\beta^2}}{2}}\\
\sqrt{\alpha+i\beta}&=\pm(\sqrt{\frac{\alpha+\sqrt{\alpha^2+\beta^2}}{2}}+\frac{\beta}{|\beta|}\sqrt{\frac{-\alpha+\sqrt{\alpha^2+\beta^2}}{2}})
\end{align*} 
\begin{definition}[Algebraic Extension]{}
Let $ F $ be a field and $ E $ be a subfield of $ F $.
\\We say that $ x\in F $ is algebraic in the field $ E $ if x satisfies the following equation: 
\begin{align*}{}{}
a_nx^n+a_{n-1}x^{n-1}+\cdots+a_1x+a_0=0 \text{ for } a_n,a_{n-1},\cdots,a_1\in E, an\neq 0
\end{align*}
if every $ x\in F $ is algebraic in $ E $, then we say that $ F $ is an algebraic extension of $ E $.
\\We say that a field $ F $ is algebraically closed if it does not have any strictly larger algebraic extension.
\\A field containing $ F $ is called an algebraic closure if it is a closed algebraic extension of $ F $ . 
\end{definition}
\textbf{Comments:}
\begin{itemize}
\item $ \mathbb{R} $ is not an algebraic extension of $ \mathbb{Q} $.
\\If this was true, then every real number would be a root of a polynomial with rational coefficients:
$$
    q_nx^n+q_{n-1}x^{n-1}+\cdots+q_1x+q_0=0 \text{ (an algebraic number)}
$$  
So the cardinality of the set of algebraic numbers is countable (trancsendental unmbers are real numbers which are not algebraic, e and $ \pi $ for example ).
\item $ Q(\sqrt{2})=\{q+\sqrt{2}q',q,q'\in Q\}$ is algebraic over $ Q $.
\item $ \mathbb{R} $ is not algebraically closed. 
\item The fundamental theorem of algebra states that any nonconstant polynomial with complex coefficients has at least one complex root.
\\ Actually this is equivalent to saying that all the roots of such a polynomial are complex.
\item The field of complex numbers is algebraically closed.
\end{itemize}
\section{Lecture 4 (02-12) -- {Conjugation and absolute value}}
\begin{definition}[Complex Conjugation]{}
Given a complex number $z=x+iy \in \mathbb{C}$, we define its complex conjugation $ \bar{z}=x-iy $ This transformation is called complex conjugation. 
\end{definition}
\textbf{Comments:}
\begin{itemize}
\item $ \bar{\bar{z}}=z $
\item  We define the real part of $ z=x+iy $ as $ Re(z)=x=\frac{z+\bar{z}}{2} $ and the imaginary part of z as $ Im(z)=y=\frac{z-\bar{z}}{2i} $ 
\item  $ \overline{z+w}=\bar{z}+\bar{w}, \bar{zw}=\bar{z}\bar{w} $: complex conjugation defines an isomorphism $ \mathbb{C}\rightarrow\mathbb{C} $  
\item $\overline{(\frac{z}{w})}=\frac{\bar{z}}{\bar{w}} $
\item if R is any rational function, then $ \overline{R(z_1,z_2,\cdots,z_n)}=R(\bar{z_z},\bar{z_2},\cdots,\bar{z_n}) $
\\In particular, \begin{align*}{}{}
a_nz^n+\cdots+a_1z+a_0=0\\
\Rightarrow \bar{a_n}\bar{z}^n+\cdots+\bar{a_1}\bar{z}+\bar{a_0}=0
\end{align*} 
\end{itemize}
\begin{definition}[absolute value]{}
Given a complex number $ z \in \mathbb{C} $, we define its absolute value, denoted by $$ |z|=\sqrt{z\bar{z}} $$
\end{definition}
\textbf{Comments:}
\begin{itemize}
\item If z is real, then $ \bar{z}=z $
\item we say that z is purely imaginary if $ Re(z)=0 $, iff $ \bar{z}=-z $ 
\item Then if z is real, |z| coincides with the traditional definition of absolute value on $\mathbb{R}$
\item $ z\bar{z}=(x+iy)(x-iy)=x^2-{(iy)}^2=x^2+y^2\geq0 $ 
\item Vector space (V,+,scalar multiplication) over a field $ \mathbb{F}(Q,R,C) $ 
\item $ |zw|=|z||w|,|\bar{z}|=|z| $
\item $ |\frac{z}{w}|=\frac{|z|}{|w|},w\neq0 $
\item $|z_1z_2\cdots z_n|=|z_1||z_2|\cdots |z_n|  $
\item ${|z+w|}^2=(z+w)(\bar{z}+\bar{w})={|z|}^2+{|w|}^2+z\bar{w}+\bar{z}w=|z|^2+|w|^2+2Re(z\bar{w}) $
\item $ {|z+w|}^2+{|z-w|}^2=2{|z|}^2+2{|w|}^2 $ 
\end{itemize}
\begin{lemma}[Triangle inequality]{}
If $ z,w\in \mathbb{C} $ then, $ |z+w|\leq |z|+|w| $  
\end{lemma}
\textbf{Proof:}
\\Note that if $ a=\alpha+i\beta $ then 
\begin{align*}{}{}
-|a|\leq Re(a)=\alpha&\leq |a|=\sqrt{\alpha^2+\beta^2}\\
\Rightarrow {|z+w|}^2=|z|^2+|w|^2+2Re(z\bar{w})&\leq |z|^2+|w|^2+2|z||w|={(|z|+|w|)}^2
\end{align*}
\textbf{Comments:}
\\Assume that z and w are such that $ |z+w|=|z|+|w| $
$$
    \Rightarrow |z||w|=Re(z\bar{w}) \Leftrightarrow z\bar{w}\geq 0
$$ 
\\We proved that absolute value is a norm (which is a good notion of distance):
\begin{itemize}
\item $|z|=0 \Leftrightarrow z=0 \text{ and } |z|\geq0, \forall z\in\mathbb{C}$
\item $ |az|=|a||z|,\forall a, z \in \mathbb{C} $
\item $ |z+w|\leq |z|+|w| $
\item  $(R^d,+,\underbrace{|| \text{ }||}_{\text{Euclidean norm}}) , ||(x_1,\cdots,x_d)||=\sqrt{{x_1}^2+\cdots+{x_d}^2} $
\end{itemize}
\begin{lemma}[Cauchy inequality]{}
If $ z_1,\cdots,z_n,w_1,\cdots,w_n\in\mathbb{C} $ ,
$$
    |\sum_{i=1}^{n}z_iw_i|\leq \sqrt{\sum_{i=1}^{n}{|z_i|}^2}\sqrt{\sum_{i=1}^{n}{|w_i|}^2}
$$ 
\end{lemma}
\textbf{Proof:}
\\Let $ \lambda\in\mathbb{R}  $ and consider
$$
    \sum_{i=1}^{n}{|z_i-\lambda w_i|}^2=\sum_{i=1}^{n}{|z_i|}^2-2 Re\bar{\lambda}(\sum_{i=1}^{n}z_i\bar{w_i})+|\lambda|^2\sum_{i=1}^{n}{|w_i|}^2
$$ 
Choose
$$
    \lambda= \frac{\sum_{i=1}^{n}z_i\bar{w_i}}{\sum_{i=1}^{n}{|w_i|}^2}
$$ 
Then,
$$
    0\leq \sum_{i=1}^{n}{|z_i|}^2-\frac{{|\sum_{i=1}^{n}z_i\bar{w_i}|}^2}{\sum_{i=1}^{n}{|w_i|}^2}
$$ 
\section{Recitation 2 (02-14)}
holomorphic functions $ f:U\subseteq \mathbb{C}\rightarrow\mathbb{C} $ s.t.
$$
    \lim_{z\rightarrow z_0}\frac{f(z)-f(z_0)}{z-z_0}=f'(z_0),\forall z_0\in U
$$  
\begin{definition}[Analytic function]{}
Let $ f :U\subseteq \mathbb{C}\rightarrow\mathbb{C}$ ,Then $ f(\cdot)  $ is said to be analytic at $ z_0\in U $ if $\exists   \{a_n\}\in\mathbb{C}$ and radius r>0
such that$$
    f(z)=\sum_{n=0}^{\infty}a_n{(z-z_0)}^n,\forall z\in U \text{ with } |z-z_0|<r
$$ 
where $ r\leq R=\lim_{n\rightarrow+\infty}|a_n|^{-\frac{1}{n}} $ the radius of convergenece 
\end{definition}
Notice that if $ f(\cdot) $ is analytic, then it is holomorphic.$ (\Leftrightarrow)$
$$
    f'(z)=\pdv{f}{z}=\sum_{n=1}^{\infty}na_n{(z-z_0)}^{n-1},\forall z\in U \text{ with } |z-z_0|<r\leq R =\lim_{n\rightarrow+\infty}(|a_n|^{-\frac{1}{n}})
$$ 
Analytic function can be constructed:
\\ Take a sequence $\{a_n\}\in \mathbb{C}$ and we consider the power series.
$$
    f(z)=\sum_{n=0}^{\infty}a_nz^n \text{ with } |z|<R = \lim_{n\rightarrow+\infty}|a_n|^{1\frac{1}{n}}$$ 
This function f(z) is actually analytic on the disk $ D(o,R)$.
\\$ \forall z_0\in D(0,R)\text{ and }0<s<R-|z-0| $ Let $ |z-z_0|<s\text{  i.e. }z\in D(z_0,s) $  
Then,$ |z_0|+|z-z_0|<R $ and we want ot express the f(z) into a desired form.
\\Note that
$$
    \sum_{n=1}^{\infty}\underbrace{(|a_n|+|z-z_0|)^n}_{<R}=\sum_{n=0}^{\infty}|a_n|(\sum_{k=0}^{n}\begin{pmatrix}n\\k\end{pmatrix}|z_0|^{n-k}|z-z_0|^k)<\infty
$$  
converges on $ z\in D(z_0,s) $ 
\\which yields
$$
\sum_{n=0}^{\infty}a_n(\sum_{k=0}^{n}\begin{pmatrix}n\\k\end{pmatrix}z_0^{n-k}(z-z_0)^k) \text{ converges absolutely in } D(z_0,s)
$$ 
Then we can interchange the order of summation and obtain
$$
    f(z)=\sum_{n=0}^{\infty}\sum_{k=0}^{n}a_n\begin{pmatrix}n\\k\end{pmatrix}z_0^{n-k}(z-z_0)^k=f(z)=\sum_{k=0}^{\infty}(\sum_{n=k}^{\infty}a_n\begin{pmatrix}n\\k\end{pmatrix}z_0^{n-k})(z-z_0)^k
$$ 
showing f(z) is the sum of a power series on $ D(z_0,s)  $ and is thus analytic at $ \forall z_0\in D(0,R) $
\begin{definition}[Inverse mapping theorem(local)]{}
 Take $ f:U\subseteq \mathbb{C}\rightarrow\mathbb{C}  $ analytic, Assume $ z_0\in U $ with $ f'(z_0 )\neq0$
 \\Then $ f(\cdot) $ is a local isomorphism at $ z_0\in U $ This means that $ \exists W\subseteq U\text{ s.t. }f(\cdot)  $ is injective on W and is thus a bijection from W to f(W)=V.
 \\And such that $ V\subseteq \mathbb{C} $ and its inverse $ g=f^{-1}:V\rightarrow W $ is also analytic.    
\end{definition}  
Indeed, we know $ f:U\rightarrow \mathbb{C} $ is holomorphic. And its Jacobian is nonzero at $ z_0 $
\\Hence, $ \exists W\subseteq U $ such that f is diffieomorphism from W onto $ f(W)=V\subseteq \mathbb{C} $ 
\\Since the Jacobian of $ g=f^{-1} $ on V is the inverse of the Jacobian of f on W,by Cauchy-Riemann equations, $ g:V\rightarrow W $  is also holomorphic. 
\\Assume w.l.o.g. $ f(z_0)=z_0,f'(z_0)=1 $, then, we cna write
$$
    f(z)=z-\sum_{n=2}^{\infty}a_n{z}^n,z\in U\cap B_R(0)
$$  
Now that f(g(z)) =z,$ \forall z\in V $ on some $ B_\zeta(0) $ we can solve this equation by picking
$$
    g(z)=z+\sum_{n=2}^{\infty}b_n{z}^n
$$   
with coefficients $ b_n=P_n(a_2,\cdots,a_n,b_1,\cdots,b_{n-1}) $ Here,$ b_n $ is a polynomial with nonnegative coefficients.
\\Soving this recursively, we show the existence and uniqueness for the power series expansion of the inverse map $ g:V\rightarrow W $
\\It remains to show that the positive radius of convergence of $g(\cdot)$ 
\\Select some A>0 sufficiently large such that$$
    |a_n|\leq A^n,\forall n\geq1 
$$ 
Then, we consider the sum$$
    F(z)=z-\sum_{n=2}^{\infty}A^nz^n=z-\frac{A^2z^2}{1-Az},\forall z\in\mathbb{C} \text{ with }|z|<\frac{1}{A}
$$ 
Its inverse G(z) is computed with the form
$$
    G(z)=\frac{1+Az-\sqrt{(1+Az)^2-4zA(A+1)}}{2A(A+1)}
$$ 
$ G(\cdot) $ is analytic with the expression 
$$
    G(z)=z+\sum_{n=2}^{\infty}B_nz^n
$$ 
Here $ B_n=P_n(A^2,\cdots,A^n,B_1,\cdots,B_{n-1}) $ where $ P_n $ is the same polynomial with nonnegative coefficients.
\\Thus $ |a_n|\leq A^n $ implies $ |b_n|\leq B \forall n\in N $   
\\Thus $g(z)=z+ \sum_{n=2}^{\infty}b_nz^n $ has at least th eradius of convergence as large as that of $ G(\cdot) $ 
\begin{align*}{}{}
g'(f(z_0))&\neq0\\
&=\frac{1}{f'(x)}
\end{align*}
\begin{definition}[open mapping theorem]{}
Take analytic $ f:U\subseteq \mathbb{C}\rightarrow\mathbb{C} $, s.t. f is nonconstant in a neighborhood of z,$ \forall z \in U  $  , then f is an open mapping, i.e. $ \forall V\subseteq Uf(V) $ is open subset in $ \mathbb{C} $
\end{definition}
Take any $ z_0\in V V\subseteq U$ and we denote$$
    f(z)=\sum_{n=0}^{\infty}a_n{(z-z_0)}^n,\forall |z-z-0|<R=\lim_{n\rightarrow+\infty}|a_n|^{-\frac{1}{n}}
$$ 
And we let $u(z)=f(z+z_0)-f(z_0)$, then , clearly the power series $$
    u(z)=\sum_{n=1}^{\infty}a_n{z}^n \text{ has the same radius of convergence } R>0
$$ 
Since f(z) is nonconstant in at $ z_0 $ , we can find some $ m\geq1 $ s.t.$$
    u(z)=\sum_{n=m}^{\infty}a_n{z}^n \text{ with } a_m\neq 0
$$ 
If we can show exists analytic function v(z) with $v'(0)\neq0   $ s.t.$ u(z)=v(z)^m $ then the assertion is verified.
\\And we define $ b_k=\frac{a_{m+k}}{a_m} $ for $ k\geq1 $ and consider the power$$
    g(z)=\sum_{k=1}^{\infty}b_k{z}^k
$$ 
and $u(z)=a^mz^m(1+g(n))$, Now we write $ k(z)=(1+g(z))^\frac{1}{m} -1$ 
\\then $(1+k(z))^m=1+g(z)$, let$$
    v(z)=a_m^{\frac{1}{m}}z(1+k(z))=a_m^{\frac{1}{m}}z+a_m^{\frac{1}{m}}zk(z)
$$ 
Then we have $v(z)^m=u(z)$ and v(z) is analytic with $v'(0)\neq0$
\\Hence,$ \exists \text{ open disk } D(0,r) \text{ s.t. } V(D)\supseteq D':=D(o,r')$ 
\\And then, the image of D' under $ z\rightarrow z^m $ is again an open disk, verifying the assertion.  
\section{Lecture 5 (02-17) -- {The geometric representation of complex numbers}}
\begin{definition}[Euler's formula]{}
$$
    e^{i\theta}=cos\theta+isin\theta,\theta\in\mathbb{R}
$$
\end{definition}
Stereographic projection:
\subsection{Geometric multiplication}
\begin{align*}{}{}
a&=(\alpha, \beta)=\alpha+i\beta\\
&=rcos\theta+irsin\theta\\
&=r(cos\theta+isin\theta)\\
r=|a|&=\sqrt{\alpha^2+\beta^2}\\
cos\theta&=\frac{\alpha}{r},sin\theta=\frac{\beta}{r}\\
sin\theta&=\frac{\beta}{r}
\end{align*}
\begin{definition}[argument of a complex number]{}
Given $ a\in C $ and its polar representation$$
    a=r(cos\theta+isin\theta)
$$ 
we call $ \theta $ the argument of a and denote it by $$ \theta=arg(a) $$
\end{definition}
\begin{lemma}[]{}
Let $ a_1=r_1(cos\theta_1+isin\theta_1)\text{ and }a_2=r_2 (cos\theta_2+isin\theta_2)$ \\
arg($ a_1a_2 $)=arg($ a_1 $)+arg($ a_2 $)
\end{lemma}
\textbf{Proof:}
\begin{align*}{}{}
a_1a_2&=r_1r_2(cos\theta_1+isin\theta_1) (cos\theta_2+isin\theta_2)\\
&=r_1r_2(cos\theta_1cos\theta_2-sin\theta_1sin\theta_2+isin\theta_1cos\theta_2+icos\theta_1sin\theta_2)\\
&=r_1r_2(cos(\theta_1+\theta_2)+isin(\theta_1+\theta_2))
\end{align*}
\textbf{Comments:}
\begin{itemize}
\item we will later define the function $ e^z ,z\in \mathbb{C}$\\
We will show that $ e^{z_1}e^{z_2}=e^{z_1+z_2} $\\
And also $ e^{i\theta}=cos\theta+isin\theta $\\
Then $ a_1a_2=r_1r_2e^{i\theta_1}e^{i\theta_2}=r_1r_2e^{i(\theta_1+\theta_2)} $   
\end{itemize}
\subsection{The binomial equation}
\begin{align*}{}{}
(a+b)^n&=\sum_{k=0}^{n}\begin{pmatrix}n\\k\end{pmatrix}a^{n-k}b^k\\
&=\sum_{k=0}^{n-1}\frac{n!}{k!(n-k)!}a^{n-k}b^k
\end{align*}
Note that if $a=a=r(cos\theta+isin\theta)$\\
Then for $ n\geq0 $ and we want to check it is true for $ n=-1 \text{ and } n\in Z$
\begin{align*}{}{}
a^n&=r^n(cosn\theta+isinn\theta)\\
a^{-1}&=\frac{1}{r(cos\theta-isin\theta)}\\
&=r^{-1}\frac{cos\theta-isin\theta}{(cos\theta+isin\theta)(cos\theta-isin\theta)}\\
&=r^{-1}(cos\theta-isin\theta)\\
&=r^{-1}(cos(-\theta)+isin(-\theta))
\end{align*}
\begin{lemma}[de Maivre]{}
\begin{align*}{}{}
    {(\cos\theta-i\sin\theta)}^n=\cos(n\theta)-i\sin(n\theta)
\end{align*}
\end{lemma}
\subsection{Roots of complex numbers}
\begin{align*}{}{}
-1=1(\cos\pi+i\sin\pi)\\
1=(-1)^2=(\cos\pi+i\sin\pi)^2=\cos2\pi+i\sin2\pi\\
\end{align*}
\textbf{Cube roots of 1:}
\begin{align*}{}{}
z^3-1=0\\
z^3-1=(z-1)(z^2+z+1)=0\\
\Delta=1-4=-3<0\\
z_1=\cos\frac{2\pi}{3}+i\sin\frac{2\pi}{3}\\
z_2=\cos\frac{4\pi}{3}+i\sin\frac{4\pi}{3}
\end{align*}
\begin{lemma}[]{}
Let $ a\in \mathbb{C} $ and $ n\geq1 $ , Then the equation$$
    z^n=a,a=r(\cos\theta+i\sin\theta)
$$ has only n distinct solutions.(called the n-th roots of a) given by
$$
    a=r^{\frac{1}{n}}(\cos\frac{\theta+2k\pi}{n}+i\sin\frac{\theta+2k\pi}{n}),k=0,1,\cdots,n-1
$$ 
\end{lemma}
\begin{proof}
    \begin{align*}{}{}
    z=e(\frac{\theta+2k\pi}{n}+i\sin\frac{\theta+2k\pi}{n}),\text{ where } e^n=r\\
    \end{align*}
\end{proof}
\section{Lecture 6 (02-19) -- {Riemann sphere}}
\begin{definition}[stereographic projection]{}
We will define a mapping bwtween the Riemann sphere and the extended complex plane $ \mathbb{C}\cup\{\infty\} $ called the stereographic projection.
\end{definition}
Riemann sphere has radius 1
\begin{align*}{}{}
z&=a(x_1+ix_2),a\in\mathbb{R}\\
&=\frac{x_1+ix_2}{1-x_3}
\end{align*}
\begin{definition}[stereographic projection]{}
we define the stereographic projection as the mapping$$
    S:S-\{(0,0,1)\}\rightarrow \mathbb{C}$$
    and $$
    S(x_1,x_2,x_3)=\frac{x_1+ix_2}{1-x_3}
    $$ 
\end{definition}
\textbf{Comments:}
We can extend the domain of the stereographic projection to all of S if we add a point "$ \infty $ " to $ \mathbb{C} $ and define $ \bar{\mathbb{C}}=\mathbb{C}\cup\{\infty\} $ extended complex plane,$$
    S(0,0,1)=\infty
$$   
\begin{itemize}
\item $ S:S\rightarrow\bar{\mathbb{C}} $ is a bijection 
\item It is possible to define a topology ( this is the collection of open sets) on $ \bar{\mathbb{C}} $ s.t. its restriction to $ \mathbb{C} $ coincides with the open sets in $ \mathbb{C} $
\end{itemize}
\begin{align*}{}{}
z=\frac{x_1+ix_2}{1-x_3}\\
|z|^2=\frac{x_1^2+x_2^2}{(1-x_3)^2}=\frac{1-x_3^2}{(1-x_3)^2}=\frac{1+x_3}{1-x_3}\\
\rightarrow (1-x_3)|z|^2=1+x_3\\
\rightarrow x_3=\frac{|z|^2-1}{|z|^2+1}\\
z+\bar{z}=2\frac{x_1}{1-x_3}\\
x_1=\frac{(z+\bar{z})(1-x_3)}{2}\\
x_1=\frac{z+\bar{z}}{|z|^2+1}\\
x_2=\frac{z-\bar{z}}{i(|z|^2+1)}
\end{align*}
Consider a circle on S:
$$
    \alpha_1x_1+\alpha_2x_2+\alpha_3x_3=\alpha_0 
$$ show that this is the general equation of a circle on the Riemann sphere.
\begin{align*}{}{}
\alpha_1^2+\alpha_2^2+\alpha_3^2&=1,\alpha_1,\alpha_2,\alpha_3\in\mathbb{R}\\
\end{align*}
We want to find the locus of this circle in $ \mathbb{C} $ under S.
\begin{align*}{}{}
\Leftarrow \alpha_1(z+\bar{z})-i\alpha_2(z-\bar{z})+\alpha_3(|z|^2-1)=2\alpha_0(|z|^2+1), z=x+iy\\
2\alpha_1x+2\alpha_2y+\alpha_3(x^2+y^2-1)=\alpha_0(x^2+y^2+1)\\
(\alpha_3-\alpha_0)(x^2+y^2)+2\alpha_1x+2\alpha_2y=\alpha_0+\alpha_3\\
\end{align*}
For $ \alpha_3\neq\alpha_0 $, this is the equation of a circle in $ \mathbb{C} $
\\For $ \alpha_3=\alpha_0 $, this is the equation of a line in $ \mathbb{C} $
\\\textbf{Comments:}    
\\Formula for the distance between two points $ z,z'\in\mathbb{C}$ in S:$$
    d(z,z')=||S^{-1}(z)-S^{-1}(z')||_2=\frac{2|z-z'|}{\sqrt{(1+|z|^2)(1+|z'|^2)}}
$$  
This notion of distance is a metric which is equivalent to the metric in $ \mathbb{C} $ included by the Euclidean norm.
\section{Lecture 7 (02-24) -- {Complex function}}
Analysis of complex functions:differentiable,etc
$ R\rightarrow R,R\rightarrow C, C\rightarrow R, C\rightarrow C $ 
\\$  C\rightarrow C $ :continuity, differentiability$ \Leftrightarrow $analiticity
\\twice differentiability,$ \infty $ differentiability($ C^{\infty}(\mathbb{R}) $)
\begin{definition}[analiticity]{}
$f(x+h)=\sum_{n=0}^{\infty}\frac{h^n}{n!}f^{(n)}(x)$
\end{definition} 
\begin{definition}[continuity]{}
Consider a funtion f:$ C\rightarrow C $, then we say f has a limit L when x tends to a ,written as$$
    \lim_{z\rightarrow a}f(z)=L
$$  
if $ \forall \epsilon>0,\exists \delta $ s.t. $ |f(z)-L|<\epsilon\text{ whenever } |z-a|<\delta  $
\\we say that f is continuous at a if $ \lim_{z\rightarrow a}f(z)=f(a) $
\\we say that f is continuous if it is continuous at every point where it is defined.
\end{definition} 
\textbf{Comments:}
This defination of continuity is the standard defination of continuity in a topology space. In this case, the topological space is$$
    (C,T)\rightarrow (C,T) \Leftrightarrow \text{ f is continuous iff } f^{-1}(0)\text{ is open in } 0\in T \text{ open}
$$ T is the subset of C which are open sets: a union of open balls $ B(z,r)=\{z'\in C,|z-z'|<v\} $ 
\subsection{analiticity}
\begin{definition}[differentiability and analiticity]{}
Given $ f:C\rightarrow C $ we say that f is differentiable at $ a\in C $ if the limit exists: $$
    \lim_{h\rightarrow0}\frac{f(a+h)-f(a)}{h}=\lim_{z\rightarrow a}\frac{f(z)-f(a)}{z-a}=f'(a)
$$   
We say that f is analytic if it is differentiable at every point where it is defined.
\end{definition}
\textbf{Comments:}
In general, we will assume that the set of point where $f: C\rightarrow C $ is defined is an open set ($ O=\bigcup B(x,\epsilon_x) $ )
\\In particular, this is being assumed in the defination grown above.
\\If f is differentiable at a, then f is continuous at a.
\begin{align*}{}{}
f(z+h)-f(z)&=\frac{f(z+h)-f(z)}{h}h\\
\rightarrow |f(z+h)-f(z)|&\leq \underbrace{|\frac{f(z+h)-f(z)}{h}}_{|f'(z)|}\underbrace{||h|}_{\rightarrow0}
\end{align*}
Of course f'(z) when it exists is called the derivative of f at z.\\
$ f:C\rightarrow C $  f is differentiable at $ z=x+iy $ 
\begin{align*}{}{}
f(z)=u(x,y)+iv(x,y)
\end{align*}
Then \begin{align*}{}{}
f'(z)&=\lim_{h\in \mathbb{R}\rightarrow0}\frac{f(z+h)-f(z)}{h}\\
&=\lim_{h\rightarrow0}\frac{u(x+h,y)+iv(x+h,y)-u(x,y)-iv(x,y)}{h}\\
&=\lim_{h\rightarrow0}\frac{u(x+h,y)-u(x,y)}{h}+i\lim_{h\rightarrow0}\frac{v(x+h,y)-v(x,y)}{h}\\
&=\pdv{u}{x}+i\pdv{v}{x}
\end{align*}  
On the other hand,
\begin{align*}{}{}
    f'(z)&=\lim_{k\rightarrow0}\frac{f(z+ik)-f(z)}{ik}\\
    &=\lim_{k\rightarrow0}\frac{u(x,y+k)+iv(x,y+k)-u(x,y)+iv(x,y)}{ik}\\
&=\frac{1}{i}\pdv{u}{y}+\pdv{v}{y}\\
&=\pdv{v}{y}-i\pdv{u}{y}
\end{align*} 
\begin{lemma}[Cauchy-Riemann equations]{}
Assume that $ f:C\rightarrow C $ is differentiable at z=x+iy with f=u+iv,Then$$
    \pdv{u}{x}=\pdv{v}{y}\text{ and }\pdv{u}{y}=-\pdv{v}{x}
$$ 
\end{lemma}
\textbf{Comments:}
\begin{itemize}
\item Assume that the existence of f'(z) lets me differentiate again $ u_x,u_y,v_x,v_y $. Then,
$$
    \Delta u=\pdv[2]{u}{x}+\pdv[2]{u}{y}=\pdv{u}{x}{y}-\pdv{u}{y}{x}=0
$$ and$$
    \Delta v=\pdv[2]{v}{x}+\pdv[2]{v}{y}=\pdv{v}{x}{y}-\pdv{v}{y}{x}=0
$$ 
u and v should be harmonic.
\item The existence of f'(z) implies the existence of $ u_x,u_y,v_x,v_y $ 
\begin{itemize}
\item  $ f'(z)=\pdv{u}{x}+i\pdv{v}{x}=\pdv{v}{y}+i\pdv{v}{x}=\pdv{u}{y}-i\pdv{u}{y} $
\item  $ |f'(z)|^2=(\pdv{u}{x})^2+(\pdv{u}{y})^2=(\pdv{v}{y})^2+(\pdv{v}{x})^2 $ 
\end{itemize}
\end{itemize}

\section{Lecture 8 (02-26)--{polynomial}}
\begin{definition}[harmonic function]{}
We say that a function $ u:R^d\rightarrow R ,d\geq1$ is harmonic if it satisfies the Laplace equation$$
    \Delta u=\pdv[2]{u}{x}+\pdv[2]{u}{y}=0$$
\end{definition}
\textbf{Comments:}
Weyl's Lemma(PDE):
\\If u is a function that is weakly harmonic, $$
    \int u \Delta \phi dx=0 ,\forall \phi \text{ smooth}
$$ 
Then u is pointwise harmonic and infinitely differentiable.
\begin{lemma}[]{}
Assume that u and v are functions which have continuous first order partial derivatives, and that satisfy the Cauchy-Riemann equations\\
Then $f=u+iv $ is analytic, with a continuous derivative $f'(z)$
\end{lemma}
\textbf{Proof:}
The fact that u and v have continuous partial derivative implies that $ f=(u,v) $ is differentiable$$
    \frac{f(x+h,y+k)-f(x,y)}{h+ik}=\pdv{f}{x}h+\pdv{f}{y}ik+\mathcal{E}(h,k)\text{ (goes to 0 faster than h+ik)}
$$  
\subsection{polynomials}
The polynomial functions will give us some framework which will enable us to develop some efficient integration techniques.
\\Two concepts will be important: singularities and zeros of functions.
\\ a is a zero of f if $ f(a)=0 $
\\ a is a singularity of f if f is not defined at a.
\textbf{Comments:}
\begin{itemize}
\item The constant function $ f:C\rightarrow C f(z)=constant$ is analytic
\item The function $ f(z)=z $ is analytic$$
    f'(z)=\lim_{h\rightarrow0}\frac{f(z+h)-f(z)}{h}=1
$$ 
\item $ f(z)=z^2 $ and $ f'(z)=\lim_{h\rightarrow\infty}\frac{(z+h)^2-h^2}{h}=2z $
\item Similarly, using the binomial theorem, you can show that $ (z^n)'=nz^{n-1} $ 
\item You can check that the product or the sum of analytic functions is analytic  
\end{itemize}
\begin{lemma}[]{}
Every polyomial $ P:C\rightarrow C $ ,$$
    P(z)=a_0+a_1z+\cdots+a_nz^n,a_n\neq 0
$$  is analytic.
\\Futhermore,
$$
    P'(z)=a_1+2a_2z+\cdots+na_nz^{n-1}
    $$
\end{lemma}
\textbf{Comments:}
We will prove later the fundamental theorem of algebra which states that every complex polynomial has at least one root in C.
\\Then given the polynomial P(z) of degree n (which means that $ P(z)=a_0+a_1z+\cdots+a_nz^n,a_n\neq 0$)
can be written as$$
    P(z)=(z-\alpha_1)Q(z),\text{ where } Q \text{ is a polynomial of degree n-1}
$$
Repeating this argument for Q, and so on, $$
    P(z)=(z-\alpha_1)(z-\alpha_2)\cdots(z-\alpha_n)
$$ where $ \alpha_1,\cdots,\alpha_n $ are the roots of P, which are not necessarily distinct.
$$
    P(z)=(z-\alpha_1)^{h_1}(z-\alpha_2)^{h_2}\cdots(z-\alpha_k)^{h_k},\sum_{i=1}^{k}h_i=n,1\leq k\leq n
$$ 
\begin{definition}[]{}
Given a polynomial P written in that form with distinct roots $ \alpha_1,\cdots,\alpha_k $, $ 1\leq k\leq n $
\\we call $ h_i ,1\leq i \leq k$ the order of the zero $ \alpha_i $, when $ h_i=1 $ we will say that $ \alpha_i $ is simple.  
\end{definition}
\begin{theorem}[Luca's theorem]{}
If all the zeros of a polynomial P lies in a half-plane H, then all the zeros of $ P'(z) $ lies in the same half plane. 
\end{theorem}
\section{Lecture 9 (03-02)}
\begin{proof}
    \begin{align*}{}{}
    P(z)&=(z-\alpha_1)(z-\alpha_2)\cdots(z-\alpha_k)\\
    &=\prod_{i=1}^{k}(z-\alpha_i)\\
    P'(z)&=\sum_{i=1}^{k}\prod_{j\neq i}(z-\alpha_j)\\
    \frac{P'(z)}{P(z)}&=\sum_{i=1}^{k}\frac{1}{z-\alpha_i}
    \end{align*}
\end{proof}
\textbf{Fact:}
any half Plane H $ \in \mathbb{C} $ is determined by two complex numbers a and b so that $$
    z\in H \text{ iff }Im(\frac{z-a}{b})<0
$$ Hint: use the fact that $ \forall a,b\in \mathbb{C},bt+a,t\in \mathbb{R} $ is a line in C.
\\Assume that $ a_k\in H \text{ and }z \notin H $  then$$
    Im(\frac{a_k-a}{b})<0 \text{ and } Im(\frac{z-a}{b})\geq 0$$
    $$
        \Rightarrow Im(\frac{b}{z-a_k})<0
    $$ 
    \begin{align*}{}{}
    \Rightarrow Im(\frac{z-a_k}{b})=Im(\frac{z-a}{b}+\frac{a-a_k}{b})> 0\\
    Im(b\frac{P'(z)}{P(z)})=\sum_{k=1}^{n}Im(\frac{b}{z-a_k})<0 \text{ whenever }z\notin H\\
    \Rightarrow P'(z)\neq 0
    \end{align*}
    2.4 Rational functions\\
    2.5 Power series\\
    2.6 Exponential,trigonometric function and logarithm\\
    \subsection{2.4 Rational functions}
    We will begin the discussion about how to classify singularities:
    \\f analytic\\
    singularities: poles(isolated), essential
    \begin{align*}{}{}
    P=(z-a)^hQ\\
    f(z)\approx \frac{g(z)}{(z-a)^h}
    \end{align*}
    \begin{definition}[rational function]{}
    A rational function R is a function of the form$$
        R(z)=\frac{P(z)}{Q(z)}$$
        where P and Q are polynomials which do not have common factors.\\
        Any zeros of Q are called poles of R.\\
        We say that a pole of R has order h if the corresoponding zero of Q has order h.
    \end{definition}
    \textbf{Comments:}
    \begin{align*}{}{}
    R'(z)&=\frac{P'(z)Q(z)-P(z)Q'(z)}{Q(z)^2}\\
    &=\frac{P'(z)}{Q(z)}-P(z)\frac{Q'(z)}{Q(z)^2}
    \end{align*}
    Suppose that $ \alpha $ is a pole of R of order h: then \begin{align*}{}{}
    Q(z)&=(z-\alpha)^hQ_1(z)\\
    \Rightarrow Q'(z)&=(z-\alpha)^{h-1}Q_2(z), Q_1(\alpha),Q_2(\alpha)\neq 0
    \end{align*}
    \begin{align*}{}{}
    R'(z)=\frac{P'(z)}{Q(z)}-P(z)\frac{Q'(z)}{Q(z)^2}\\
    \frac{P'(z)}{Q(z)} \text{ has a pole }\alpha \text{ of order h }  (P'(z)\neq 0)\\
    \end{align*}
    \begin{lemma}[]{}
    If R has a pole $ \alpha $ of order h, R' has a pole $ \alpha $ of order h+1
    \end{lemma}
    \begin{definition}[pole or zero at infinity]{}
    Let R be a rational function, Consider the rational function$$
        R_1(z):=R(\frac{1}{z})
    $$ 
    We say R has a zero at infinity of order h if $ R_1 $ has a zero at 0 of order h.\\
    Similarly, we say that R has a pole at infinity of order h if $ R_1 $ has a pole at 0 of order h. 
    \end{definition}
    \textbf{Comments:}
   R is not defined at infinity. Nevertheless if $$
    \lim_{z\rightarrow\infty}R(z)=R(\infty)
   $$ exists, call it $ R(\infty) $ , I can extend the defination of R to $ \bar{\mathbb{C}} $\\
   In this case, we could say that $ \infty $ is a removable singularity \\
   If $ R(\infty)=0 $ , the $ \infty $ is a removable singularity which is a zero\\ 
\section{Lecture 10 (03-05)}
\begin{lemma}[]{}
consider a rational function
\end{lemma}
\begin{definition}[order of a rational function]{}
The order of a rational function is equal to the common number of zeros or poles(with repeatition) of R
\end{definition}
\textbf{Comments:}
The order is max\{m,n\}
\subsection{Power series}
We will recall some properties of power series.$$
    f(z)=\sum_{n=0}^{\infty}a_nz^n
$$ is the context of complex numbers
\\To study complex power series, we need to develop some topology and some notions of convergence in C.
\\$ D(\mathbb{C},||) $ this is a normed vector space over C.\begin{itemize}
\item $ |z|\geq0  $ and $ |z|=0\Leftrightarrow z=0 $
\item $ |z_1z_2|=|z_1||z_2| $
\item $ |z_1+z_2|\leq|z_1|+|z_2| $
\end{itemize} 
We can then define the concept of limits of sequence$$
    \lim_{n\rightarrow\infty}a_n=a\Leftrightarrow \lim_{n\rightarrow\infty}|a_n-a|=0
$$ 
We will need to construct limits of sequences under the assumption that a sequence is a Cauchy sequence
\\In Q, it is not true that $$
    \lim_{n\rightarrow\infty}q_n \text{ exists as a rational number even though it might exists as a real number} 
$$ 
Cauchy sequence in C:
\\We say that \{$ a_n $\} is a Cauchy sequence if $$
    \lim_{n\rightarrow\infty}\sup_{m\geq n}|a_n-a_m|=0
$$ 
\\In R any Cauchy sequence is convergent.
\begin{definition}[]{}
A normed vector space is called complete if every Cauchy sequences are convergent.
\end{definition}
\begin{itemize}
\item Q is not complete
\item R is complete
\item C is complete
\item Then to study whether or not a series is convergent, I don't have to necessarily identify its limit.
\end{itemize}
\begin{definition}[power series]{}
A power series is a series of the form$$
    f(z)=\sum_{n=0}^{\infty}a_nz^n
$$ where $ a_n\in C $ and z is a complex number or of the form $$
    f(z)=\sum_{n=0}^{\infty}a_n(z-z_0)^n
$$ where $ a_n\in C $ and $ z,z_0\in C $
\\We say that a power series is convergent at z if $$
    \lim_{n\rightarrow\infty}\sum_{k=0}^{n}a_kz^k \text{ exists}
$$ otherwise we say the power series is divergent at z.
\end{definition}
\textbf{Comments:}  
\\ A power series is a complex function (not only a complex number)
\begin{itemize}
\item Given a sequence of complex functions $ (f_n) $ , we say that it converges pointwise to f if $$
    \lim_{n\rightarrow\infty}f_n(z)=f(z)
$$ 
\item we say that if $ f_n $  converges uniformly to f if $$
    \lim_{n\rightarrow\infty}\sup_{z\in D}|f_n(z)-f(z)|=0
$$
\end{itemize}
\section{Lecture 11 (03-12)--{Exponential, trigonometric functions and logarithm}}
\begin{align*}{}{}
\bar{e^z}=e^{\bar{z}}\\
\bar{e^{ix}}=e^{-ix}\\
|e^{ix}|^2=e^{ix}e^{-ix}=1\\
e^{ix}:=R\rightarrow S=\{z:|z|=1\}\\
\end{align*}
\begin{definition}[]{}
Define the trigonometric functions as$$
    \cos z=\frac{e^{iz}+e^{-iz}}{2},\sin z=\frac{e^{iz}-e^{-iz}}{2i}
    $$
\end{definition}
\textbf{Comments:}
\begin{itemize}
\item These definitions, extend the defination of cossine and sine functions, to complex arguments.
\item Euler's formula:$$
    e^{iz}=\cos z+i\sin z
$$ 
\item From Euler's formula we can have $$
    \cos(z)^2+\sin(z)^2=1
$$ 
\end{itemize}
\begin{definition}[period of a function]{}
We say that $ c\in C $ is a period of a complex function f if $$
    f(z+c)=f(z),\forall z\in C
$$  
\end{definition}
\begin{definition}[]{}
The smallest positive period of $$
    e^{iz}
$$ will be called $ 2\pi $  
\end{definition}
Using some analysis including the intermediate value theorem, we can prove that there exists a number $ y_0>0 $ s.t.$$
    e^{iy_0}=1
$$  
\textbf{Comments:}
\begin{definition}[logarithm]{}
A logarithm of $ w\in C $ is defined as a root of th eequation$$
    e^z=w
$$  denoted by $ z=\log w $
\end{definition}
Notice that if z is a logarithm of w, then $$
    e^{z+2\pi i}=e^z
$$ $ z+2\pi i $ is also a logarithm of w.
\\\textbf{Comments:}
\begin{itemize}
\item 0 has no logarithm
\item for $ w\neq0 $ we want to find a $ z=x+iy $ such that $$
    e^z=w\Rightarrow e^x=|w|
$$ so\begin{align*}{}{}
x=\log|w|\\
\end{align*}
\end{itemize}

\section{Lecture 12 (03-19)--{Complex integration}}
\subsection{line integral}
The integral of a complex function $ f:[a,b]\rightarrow c $ as $$
    \int_{a}^{b}f(z)dz=\int_{a}^{b}u(x)dx+i\int_{a}^{b}v(x)dx
$$
We also proved that $$
    |\int_{a}^{b}f(t)dt|\leq\int_{a}^{b}|f(t)|dt
$$ 
\textbf{Comments:}
\\We want to define integrals alone a complex curve $$
    \gamma=\{z(x):\alpha\leq x\leq\beta\}
$$ 
\begin{definition}[complex curve]{}
We say that $ \gamma $ is an arc or curve (also we might use the contour) in the complex plane, if it can be represented as $$
    \gamma=\{z(t):a\leq x\leq b\}
$$ where z(t)=x(t)+iy(t) and $x:[a,b]\rightarrow R,y:[a,b]\rightarrow R$ are continuous
\end{definition}
\textbf{Comments:}
\\Peano curve: a continuous curve that fills the square
\\We say that z is differentiable if z in the representation of the arc is differentiable, so that $$
    z'(t)=x'(t)+iy'(t)
$$ We will say that an arc is regular if $ z'(t)\neq 0 $ for all $a\leq t\leq b  $ (this is convenient because then at the point z(t) the arc will have a tangent line with slope argz'(t))
\\We will also say that an arc is piecewise differentiable (or regular) if the arc is differentiable (regular) at all points except for a finite number of points where itis still continuous and it has right and left derivatives which coincide with the left and right limits of z'(t).
\begin{definition}[closed and simple arc]{}
We say that an arc is simple or a Jordan arc if $ z(t_1)=z(t_2) $ only when $ t_1=t_2 $. We say that an arc is closed or a closed curve if its initial point coincides with its final points, so that $ z(\alpha)=z(\beta) $
\\We define a simple closed arc or Jordan curve as an arc which is simple (except $ z(\alpha)=z(\beta) $ ) and closed.   
\end{definition} 
\textbf{Comments:}
\\A Jordan curve is closed, continuous, 1-1 mapping from [$ \alpha ,\beta$] with $ \alpha\text{ indentified with } \beta  \text{ to } C$
\\Jordan curve cannot be space-filling
\\A Jordan curve separate C into the interior and the exterior of the curve.(Jordan curve theorem)
\\There exists Jordan curve which  have positive area.
\begin{definition}[Line integral]{}
Let $ \gamma $ be a piecewise differentiable arc in C, and let f be a complex function defined on $ \gamma $. We define the line integral of f over $ \gamma $ as $$
    \int_{\gamma}f(z)dz=\int_{a}^{b}f(z(t))z'(t)dt 
$$
\end{definition} 
\textbf{Comments:}
\\1. This line integral is invariant under a change in the parameterization of the arc.
\\So if $ z(t):\alpha\leq t\leq \beta $ and $ t=t(\tau), a\leq \tau \leq b$,differentiable, then$$
\int_{\alpha}^{\beta}f(z(t))z'(t)dt =\int_{a}^{b}f(z(t(\tau)))z'(t(\tau))t'(\tau)d\tau=\int_{a}^{b}f(w(\tau))w'(\tau)d\tau
$$  where $ w(\tau)=z(t(\tau)) ,t(a)=\alpha,t(b)=\beta$
\\2.In this discussion arc have an orientation
\section{Lecture 13 (04-14)--{Cauchy integral theorem}}
\begin{definition}[Linear fraction or transformation]{}
A linear fraction or linear transformation is a function from C to C of the form$$
    f(z)=\frac{az+b}{cz+d},ad-bc\neq0
$$
where a,b,c,d are complex numbers, $ac-bd\neq0$
\end{definition}
\textbf{Comments:}
\begin{itemize}
\item A linear fraction is a rational function of order 1: common number of zeros and poles.
\item Each linear fraction is a bijection from C to C. As a matter of fact, the inverse of $$
    \frac{az+b}{cz+d} \text{ is } \frac{dw-b}{-cw+a}
$$ 
\item group representation
\item linear fraction map circles into circles
\end{itemize}
\begin{lemma}[]{}
Let $ a\neq b $ ,Then for every z in the line segment between a and b ,$$
    \frac{z-a}{z-b}\in [-\infty,0]
$$ 
\end{lemma}
\textbf{Proof:}
\begin{align*}{}{}
z=a+(b-a)t \text{ with }t\in[0,1]\\
\text{Then } \frac{z-a}{z-b}=\frac{(b-a)t}{(b-a)(1-t)}=\frac{t}{1-t}\\
\text{Then } \frac{z-a}{z-b}\in [0,\infty)\\
\end{align*}
Recall the defination of the winding number
$$
    n(\gamma,a)=\frac{1}{2\pi i}\int_{\gamma}\frac{1}{z-a}dz
$$ 
\begin{lemma}[]{}
As a function of a, the winding number $  n(\gamma,a)$ is constant in each region determined by $ \gamma \text{ and } O $ in the bounded region.  
\end{lemma}
\textbf{Proof:}
There is a

